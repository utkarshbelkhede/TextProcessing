{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Importing dataset into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cleaned text</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blackstone to buy EagleClaw Midstream for abou...</td>\n",
       "      <td>EagleClaw Midstream Ventures LLC, the largest ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worldwide Mobile Crusher and Screener Industry...</td>\n",
       "      <td>WireThe report has been added to offering. Acc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In a First, BP Offers Employees Shares in Rall...</td>\n",
       "      <td>Oil major BP is launching its first share awar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHAREHOLDER ALERT: Purcell Julie &amp; Lefkowitz L...</td>\n",
       "      <td>TipRanks We’ve got a full month of 2021 behind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Komatsu Australia - Komatsu Australia</td>\n",
       "      <td>Komatsu Australia Corporate Finance Pty Ltd Cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Blackstone to buy EagleClaw Midstream for abou...   \n",
       "1  Worldwide Mobile Crusher and Screener Industry...   \n",
       "2  In a First, BP Offers Employees Shares in Rall...   \n",
       "3  SHAREHOLDER ALERT: Purcell Julie & Lefkowitz L...   \n",
       "4              Komatsu Australia - Komatsu Australia   \n",
       "\n",
       "                                        cleaned text  relevance  \n",
       "0  EagleClaw Midstream Ventures LLC, the largest ...          0  \n",
       "1  WireThe report has been added to offering. Acc...          0  \n",
       "2  Oil major BP is launching its first share awar...          1  \n",
       "3  TipRanks We’ve got a full month of 2021 behind...          0  \n",
       "4  Komatsu Australia Corporate Finance Pty Ltd Cr...          0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Data\n",
    "\n",
    "train = pd.read_excel(\"../datasets/training_set.xlsx\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cleaned text</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As Blackjewel bankruptcy case enters final str...</td>\n",
       "      <td>On June 11 the court ruled it would lift the a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FG Wilson (Engineering) Ltd v John Holt &amp; Comp...</td>\n",
       "      <td>1. This is the hearing of an application by th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Personnel Policy and Performance Appraisal Sys...</td>\n",
       "      <td>Here at Komatsu we consider many aspects of ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caterpillar planning 700 job cuts in the North</td>\n",
       "      <td>US manufacturing firm Caterpillar has announce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hardman &amp; Co Research : Tritax EuroBox present...</td>\n",
       "      <td>Hardman &amp; Co Research 03-Feb-2021 / 12:45 GMT/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As Blackjewel bankruptcy case enters final str...   \n",
       "1  FG Wilson (Engineering) Ltd v John Holt & Comp...   \n",
       "2  Personnel Policy and Performance Appraisal Sys...   \n",
       "3     Caterpillar planning 700 job cuts in the North   \n",
       "4  Hardman & Co Research : Tritax EuroBox present...   \n",
       "\n",
       "                                        cleaned text  relevance  \n",
       "0  On June 11 the court ruled it would lift the a...          0  \n",
       "1  1. This is the hearing of an application by th...          0  \n",
       "2  Here at Komatsu we consider many aspects of ou...          0  \n",
       "3  US manufacturing firm Caterpillar has announce...          1  \n",
       "4  Hardman & Co Research 03-Feb-2021 / 12:45 GMT/...          0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data\n",
    "\n",
    "test = pd.read_excel(\"../datasets/testing_set.xlsx\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Text Preprocessing with varoius combination\n",
    "\n",
    "def spacy_process(text, remove_stopwords, remove_punctuation):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemma_list = []\n",
    "    for token in doc:\n",
    "        lemma_list.append(token.lemma_)\n",
    "  \n",
    "    # Filter the stopword\n",
    "\n",
    "    if remove_stopwords:\n",
    "        filtered_sentence =[] \n",
    "        for word in lemma_list:\n",
    "            lexeme = nlp.vocab[word]\n",
    "            if lexeme.is_stop == False:\n",
    "                filtered_sentence.append(word)\n",
    "    else:\n",
    "        filtered_sentence =  lemma_list\n",
    "    \n",
    "    # Remove punctuation\n",
    "    if remove_punctuation:\n",
    "        punctuations=\"?:!.,;$\\'-_\"\n",
    "        for word in filtered_sentence:\n",
    "            if word in punctuations:\n",
    "                filtered_sentence.remove(word)\n",
    "\n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Text to lowercase\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Dataframe with word-vectors in TF-IDF form and Target values\n",
    "\n",
    "def final_df(df, to_lower, remove_stopwords, remove_punctuation, is_train, cv):\n",
    "\n",
    "    # Converting Text to Lowercase\n",
    "    if to_lower:\n",
    "        df.iloc[:,0] = df.iloc[:,0].apply(lower_text)\n",
    "\n",
    "    # Text Preprocessing with combination of stopwords and punctuations removal\n",
    "    df.iloc[:,0] = df.iloc[:,0].apply(spacy_process, args=(remove_stopwords, remove_punctuation))\n",
    "\n",
    "    # TF-IDF form\n",
    "    if is_train:\n",
    "        x = cv.fit_transform(df.iloc[:,0])\n",
    "    else:\n",
    "        x = cv.transform(df.iloc[:,0])\n",
    "\n",
    "    # TF-IDF form to Dataframe\n",
    "    temp = pd.DataFrame(x.toarray(), columns=cv.get_feature_names_out())\n",
    "\n",
    "    # Droping the text column\n",
    "    df.drop(df.iloc[:,0].name, axis = 1, inplace=True)\n",
    "\n",
    "    # Returning TF-IDF form with target\n",
    "    return pd.concat([temp, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with various combination and returns y_test and y_pred\n",
    "\n",
    "def train_model(model, train, test, to_lower, remove_stopwords, remove_punctuation, cv):\n",
    "\n",
    "    # Training Preprocessing\n",
    "    train = final_df(train, to_lower, remove_stopwords, remove_punctuation, True, cv)\n",
    "\n",
    "    # Spliting training dataset\n",
    "    X_train = train.iloc[:,:-1]\n",
    "    y_train = train.iloc[:,-1]\n",
    "\n",
    "    # Testing Preprocessing\n",
    "    test = final_df(test, to_lower, remove_stopwords, remove_punctuation, False, cv)\n",
    "\n",
    "    # Spliting testing dataset\n",
    "    X_test = test.iloc[:,:-1]\n",
    "    y_test = test.iloc[:,-1]\n",
    "\n",
    "    # fitting the model\n",
    "    model = model.fit(X_train, y_train)\n",
    "\n",
    "    # calculating y_pred\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before Training ReadME\n",
    "\n",
    "In function **train_model**,\n",
    "\n",
    "The Train and Test Dataset should consist of exactly two column,\n",
    "1. Text data\n",
    "2. Target values\n",
    "\n",
    "Else you would get an Error :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       168\n",
      "           1       0.91      0.67      0.77        79\n",
      "\n",
      "    accuracy                           0.87       247\n",
      "   macro avg       0.89      0.82      0.84       247\n",
      "weighted avg       0.88      0.87      0.87       247\n",
      "\n",
      "Accuracy Score : 87.45 %\n"
     ]
    }
   ],
   "source": [
    "# Combination 1\n",
    "\n",
    "# Model                 - Logistic\n",
    "# Max Features          - 500\n",
    "# Mono-Gram             - Yes\n",
    "# Lowercase             - True\n",
    "# Removed Stopwords     - Yes\n",
    "# Removed Punctuation   - Yes\n",
    "\n",
    "model = LogisticRegression()\n",
    "cv = TfidfVectorizer(ngram_range=(1, 1), max_features = 500)\n",
    "\n",
    "y_test, y_pred = train_model(model, train.iloc[:,1:], test.iloc[:,1:], to_lower=True, remove_stopwords=True, remove_punctuation=True, cv=cv)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score : {:.2f} %\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       168\n",
      "           1       0.93      0.68      0.79        79\n",
      "\n",
      "    accuracy                           0.88       247\n",
      "   macro avg       0.90      0.83      0.85       247\n",
      "weighted avg       0.89      0.88      0.88       247\n",
      "\n",
      "Accuracy Score : 88.26 %\n"
     ]
    }
   ],
   "source": [
    "# Combination 2\n",
    "\n",
    "# Model                 - Random Forest\n",
    "# Max Features          - 500\n",
    "# Mono-Gram             - Yes\n",
    "# Lowercase             - True\n",
    "# Removed Stopwords     - Yes\n",
    "# Removed Punctuation   - Yes\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=3, oob_score=True, n_estimators=100, criterion=\"gini\")\n",
    "cv = TfidfVectorizer(ngram_range=(1, 1), max_features = 500)\n",
    "\n",
    "y_test, y_pred = train_model(model, train.iloc[:,1:], test.iloc[:,1:], to_lower=True, remove_stopwords=True, remove_punctuation=True, cv=cv)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score : {:.2f} %\".format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.google.com/document/d/1GtPdkkekYPDRHfDmqaPDNA0euV1LT63qXtjm6EcPvIk/edit?usp=sharing\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "\n",
    "https://towardsdatascience.com/complete-machine-learning-pipeline-for-nlp-tasks-f39f8b395c0d\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2022/06/an-end-to-end-guide-on-nlp-pipeline/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "https://saurabhy27.medium.com/tf-idf-monogram-bi-gram-and-tri-gram-and-python-implementation-f343385b62a4\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
    "\n",
    "https://www.geeksforgeeks.org/python-program-to-convert-a-list-to-string/\n",
    "\n",
    "https://stackoverflow.com/questions/12182744/python-pandas-apply-a-function-with-arguments-to-a-series\n",
    "\n",
    "https://medium.com/mlearning-ai/nlp-03-lemmatization-and-stemming-using-spacy-b2829becceca\n",
    "\n",
    "https://sparkbyexamples.com/pandas/pandas-drop-multiple-columns-by-index/\n",
    "\n",
    "https://stackoverflow.com/questions/28103992/tfidf-vectorizer-giving-error\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/issues/19953\n",
    "\n",
    "https://www.digitalocean.com/community/tutorials/pandas-dataframe-apply-examples\n",
    "\n",
    "https://www.geeksforgeeks.org/part-speech-tagging-stop-words-using-nltk-python/\n",
    "\n",
    "https://towardsdatascience.com/text-normalization-with-spacy-and-nltk-1302ff430119\n",
    "\n",
    "https://github.com/manfye/spacy-nltk-text-normalization/blob/main/spacy-vs-nltk-text-normalization.ipynb\n",
    "\n",
    "https://spacy.io/usage/processing-pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('text_processing': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11d55a647d603ef0b5906186ef5add98ecfdb5efac7d6ebe2269a976a4550bda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
